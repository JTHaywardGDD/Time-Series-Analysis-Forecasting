{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/logo.png align='right' width=200>\n",
    "\n",
    "# Time Series Aggregations\n",
    "\n",
    "## Goal\n",
    "\n",
    "Our next step is to get introduced to a real time series dataset and learn some fundamental analysis techniques.\n",
    "\n",
    "We shall first focus on how to group the data by time periods.\n",
    "\n",
    "## Program\n",
    "- [Reading in Time Series Data](#read)\n",
    "- [Aggregations: `resample()`](#agg1)\n",
    "- [Aggregations: `transform()`](#agg2)\n",
    "- [Summary](#sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read'></a>\n",
    "\n",
    "## Reading in Time Series Data\n",
    "<img src=images/plug.jpeg  width=200>\n",
    "\n",
    "Throughout the this notebook we will use the *household power consumption* dataset. It comes from [UCI ML repo](https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption) and contains detailed power consumption time series data of a single household in Paris between 2006 and 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_raw = pd.read_csv('data/household_power_consumption.csv')\n",
    "power_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how our time data is currently recognised as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically timestamp data is contained in a separate column of standard strings. However, we want to make it machine-readable. In order to achieve this, we can set `parse_dates` with the list of columns to be converted to Pandas timestamp when reading the data with `pd.read_csv`. This automatically identifies the format of the dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_parsed = pd.read_csv('data/household_power_consumption.csv', parse_dates=['ts'])\n",
    "power_parsed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_parsed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit formatting may be a good idea if we suspect possible errors and non-standard formats in some of the rows. This will ensure that we get an error message if any value does not match our specified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    power_raw\n",
    "    .assign(ts=pd.to_datetime(power_raw['ts'], format='%Y-%m-%d %H:%M:%S'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then access information in the dataset using standard Pandas techniques. \n",
    "\n",
    "Below we demonstrate how to select all the data recorded on 17th December 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    power_parsed\n",
    "    .loc[power_parsed(power_parsed['ts'] >= pd.Timestamp('2006-12-17')) &\n",
    "                     (power_parsed['ts'] < pd.Timestamp('2006-12-18'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can also perform selections with `lambda` functions. They enable us to call the current version of the DataFrame (as opposed to having to refer to named variables) and allow for greater code reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    power_parsed\n",
    "    .loc[lambda df: (df['ts'] >= pd.Timestamp('2006-12-17')) &\n",
    "                    (df['ts'] < pd.Timestamp('2006-12-18'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for most time-series analysis functionality, we benefit from not only parsing the dates correctly, but also setting the dates as the index in the Pandas DataFrame. \n",
    "\n",
    "Let's illustrate the data without the datetime as index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = pd.read_csv('data/household_power_consumption.csv', \n",
    "                    parse_dates=['ts'], index_col='ts')\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is much simpler to select the dates from a particular range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.loc['2006-12-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.loc['2006-12-17':'2007-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even filter using different date formats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.loc['17th December 2006']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also provides us with an advantage with plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "power.plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to our *unformatted* data, which does not use the time data as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "power_raw.plot(x='ts', y='consumption', figsize=(16,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the x-axis is no longer nicely formatted? Pandas reads them as strings and will select x-ticks based on even intervals.\n",
    "\n",
    "We may also want to do some histograms to see how our data is distributed. \n",
    "\n",
    "Let's look at the 2006 and 2007 - do you notice a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.loc['2006'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.loc['2007'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agg1'></a>\n",
    "\n",
    "## Aggregations: `resample()`\n",
    "\n",
    "Another advantage of the datetime-index approach is that it provides us with some functionality for easy time-based aggregations. One such aggregation is `resample`. \n",
    "\n",
    "For example, we can easily calculate the _mean_ per _year_ by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.resample('Y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run the same aggregation per month `M`, week `W`, day `D` or quarter `Q`. Custom aggregation periods are also possible, for example per 4 weeks `4W` or per 3 months `3M`. See [here] for a more comprehensive list of offsets, that can be as specific as _'Business Month Begin'_.\n",
    "\n",
    "[here]: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects\n",
    "\n",
    "If the index is a timestamp that also includes times, then you can also aggregate per hour. The script below demonstrates this by calculating the mean per 3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "power.resample('3H').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.resample('3H').sum().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use general `.agg()` methods here to apply multiple aggregators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    power\n",
    "    .resample('M')\n",
    "    .agg(monthly_mean = ('consumption', 'mean'),\n",
    "         monthly_var = ('consumption', 'var'),\n",
    "         monthly_spread = ('consumption', lambda month_df: month_df.max() - month_df.min())\n",
    "        )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agg2'></a>\n",
    "\n",
    "## Aggregations: `transform()`\n",
    "\n",
    "Notice how aggregating results in a smaller DataFrame than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((\n",
    "    power\n",
    "    .resample('Y')\n",
    "    .agg('mean')   \n",
    ").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `transform()` allows to keep the original range of indices (in seconds) after aggregation. Resulting aggregated statistics then are the same for each aggregation period (each hour in our case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    power\n",
    "    .resample('Y')\n",
    "    .transform('mean')   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((\n",
    "    power\n",
    "    .resample('Y')\n",
    "    .transform('mean')   \n",
    ").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this with the `assign` method allows us to add new columns to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    power\n",
    "    .assign(monthly_mean = power.resample('M')['consumption'].transform('mean'),\n",
    "           monthly_var = power.resample('M')['consumption'].transform('var'),\n",
    "           monthly_spread = power.resample('M')['consumption'].transform(\n",
    "               lambda month_df: month_df.max() - month_df.min())\n",
    "           )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='as'></a>\n",
    "## <mark>Exercise: Resampling\n",
    "\n",
    "Transform the dataset into consecutive five-day-periods:\n",
    "\n",
    "- Show the total energy used in the five-day-periods\n",
    "\n",
    "- Find the five-day-period in which the most energy is consumed in total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/power-resampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sum'></a>\n",
    "## Summary\n",
    "\n",
    "We have covered: \n",
    "- How to properly read in time series data in Pandas, and why it is important to set the date as an index\n",
    "- How to aggregate over time periods with Pandas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
