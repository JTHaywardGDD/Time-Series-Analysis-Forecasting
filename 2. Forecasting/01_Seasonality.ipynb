{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality \n",
    "<img src=images/gdd-logo.png align='right' width=200>\n",
    "\n",
    "## Goal\n",
    "\n",
    "In this notebook we shall demonstrate how a contextual understanding (e.g. of seasons) can help our analysis.\n",
    "\n",
    "## Program\n",
    "\n",
    "- [Error-Trend-Seasonality Decomposition](#etsd)\n",
    "- [Dealing with Seasonality](#dws)\n",
    "- [Feature Engineering](#fe)\n",
    "    - [Assignment](#as1)\n",
    "- [Gradual Seasonal Filtering](#gsf)\n",
    "- [Non-Constant Seasonality](#ncs)\n",
    "    - [Assignment](#as2) \n",
    "- [Summary](#sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "For this notebook we will use a dataset that contains the total monthly passenger traffic at [Schiphol airport](https://www.schiphol.nl/en/schiphol-group/page/transport-and-traffic-statistics/) between January 1999 and March 2023. Each datapoint indicates the total number of passengers traveled via Schiphol in millions in each particular month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/schiphol.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_covid = pd.read_csv('data/schiphol_covid.csv', \n",
    "                             index_col='date', \n",
    "                             parse_dates=True,\n",
    "                             date_format=\"%Y %B\" #for pandas 2.0+\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_covid['total_passengers'] = schiphol_covid['total_passengers'] / 1000000\n",
    "schiphol_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_covid.index.freq='MS'\n",
    "schiphol_covid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify how much data we have for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    schiphol_covid\n",
    "    .resample('Y')\n",
    "    .count()\n",
    "    .tail()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the data over time we can clearly see some patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_covid.plot(figsize=(16,4));\n",
    "schiphol_covid['2004 Sep':'2006 Feb'].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These regularities can be described with some Time Series vocabulary:\n",
    "\n",
    "- **Trends** (upward / horizontal / downward)\n",
    "- **Seasonality** (predictably repeating cycles - weekly/monthly/yearly etc)\n",
    "- **Non-cyclical components** (patterns with no set repetition - for example trend breaks or random shocks) \n",
    "- **Residuals** (the remaining part of the series that cannot be further explicitly modeled)\n",
    "\n",
    "We will now investigate techniques to separate the general trend from the other fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='etsd'></a>\n",
    "## Error-Trend-Seasonality Decomposition\n",
    "\n",
    "We may want to separate the time series into the trend, the seasonality and the error component. This is called ETS decompoisition.\n",
    "\n",
    "There are various ways to perform ETS decomposition. For example, `seasonal_decompose` from  `statsmodels` library can quickly provide a simple/naïve ETS decomposition:\n",
    "\n",
    "Each datapoint is split into the following components: trend $T$, seasonality $S$ and a residual $e$.\n",
    "\n",
    "$$Y(t) = T(t) + S(t) + e_t$$\n",
    "\n",
    "The trend is achieved by applying a convolution filter (a form of smoothing) to the data. \n",
    "\n",
    "To get the seasonality, first the trend is subtracted from the time series data and then the average period is computed for this de-trended series.\n",
    "\n",
    "The error is the maining residual separating the sum of the trend and seasonality from the original time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "Decomposition = seasonal_decompose(schiphol_covid['total_passengers'], model = 'additive', period=12)  \n",
    "\n",
    "with plt.rc_context():\n",
    "    plt.rc(\"figure\", figsize=(16,10))\n",
    "    Decomposition.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the additive model, changes over time are consistently made by the same amount.\n",
    "\n",
    "If the amplitude is increasing/decreasing over time the m`model='multiplicative'` option can be used.\n",
    "\n",
    "$$Y(t) = T(t) * S(t) * e_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decomposition = seasonal_decompose(schiphol_covid['total_passengers'], model = 'multiplicative', period=12)  \n",
    "\n",
    "with plt.rc_context():\n",
    "    plt.rc(\"figure\", figsize=(16,10))\n",
    "    Decomposition.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly access the separated data points for trend `Decomposition.trend`, seasonality `.seasonal` and residuals `.resid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "schiphol_covid.plot(ax = ax)\n",
    "Decomposition.trend.plot(ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building such decompositions helps to inspect and analyze the general behavior of a time series. \n",
    "\n",
    "**Note**: We are not using these models for forecasting - our focus for now is to better understand the current data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quick way to detect any recurrent patterns in the data is by using the *autocorrelation plot*. **Autocorrelation**, defined as the correlation of a signal with a delayed copy of itself, illustrates to what extent the present of a series can be inferred from its past. Any cyclical patterns in the autocorrelation plot are likely signs of seasonal fluctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize = (16,4))\n",
    "plot_acf(schiphol_covid['total_passengers'], lags=12, ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, we notice there is more correlation with the data from 12 months ago than the data 6 months ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the months affected by COVID-19 will affect the autocorrelations. Let's compute the autocorrelations using only data from before 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol = (\n",
    "    schiphol_covid\n",
    "    .loc[:\"Dec 2019\"]\n",
    "    .copy()\n",
    ")\n",
    "schiphol.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize = (16,4))\n",
    "plot_acf(schiphol['total_passengers'], lags=12, ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see more correlation with the data from 12 months ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dws'></a>\n",
    "## Dealing with Seasonality\n",
    "Seasonality obscures the actual signal, which can complicate both understanding of the underlying processes and further forecasting. \n",
    "\n",
    "Understanding it gets us closer to what actually happens in the data ― which also means easier forecasting.\n",
    "\n",
    "One of the simplest ways to model the trend is to fit a linear regression. \n",
    "\n",
    "For now, we shall focus on the pre-covid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_periods = len(schiphol.index)\n",
    "schiphol['period_num'] = np.arange(total_periods)\n",
    "schiphol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = schiphol[['period_num']]\n",
    "y = schiphol['total_passengers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol['pass_lin_pred'] = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol[['total_passengers','pass_lin_pred']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the fit using the $R^2$ score - the closer to 1, the better the model captures the patterns in the data. Note though that this does not yet necessarily mean better forecasting ― we will get to this in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R^2 is {round(lm.score(X, y),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear regression illustrates the overall passenger traffic growth over time, but (expectably) fails to take the 2009 drop into account. This change in the trend is known as a breakpoint.\n",
    "\n",
    "One way to correct this would be to introduce a dummy term for the data points after 2009:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol['after2009'] = [1 if el>=pd.Timestamp('2009') else 0 for el in schiphol.index]\n",
    "\n",
    "X_break = (\n",
    "    schiphol[['period_num','after2009']]\n",
    "    .assign(interaction = lambda df: df.period_num*df.after2009)\n",
    ")\n",
    "X_break.loc['2008-11':'2009-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>**Question**: Why is it helpful to inclue an interaction term as well as the dummy variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_break = LinearRegression().fit(X_break, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model coefficients {lm_break.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model intercept {lm_break.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol['pass_lin_b_pred'] = lm_break.predict(X_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schiphol[['total_passengers','pass_lin_b_pred']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R^2 is {round(lm_break.score(X_break, y),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be a much better fit. It also illustrates that even though passenger traffic dropped during the 2008-2009 Crisis, post-crisis growth appears to be more rapid than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fe'></a>\n",
    "## Feature Engineering\n",
    "\n",
    "We may want to do more than just identifying the trend though. \n",
    "\n",
    "Modeling the seasonality would allow us to understand and quantify the seasonal effects. And this means an ability to model not just the average behavior, but exact values during each season.\n",
    "\n",
    "A simple way to achieve this would be to add seasonal dummy terms to the baseline linear regression. In fact, *feature engineering* can be a very powerful tool in Time Series Analysis, allowing us to capture rather complex patterns with a few simple engineered variables added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol['quarter']=schiphol.index.quarter\n",
    "\n",
    "X_quarter = schiphol[['period_num','quarter']]\n",
    "X_quarter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we use `ColumnTransformer` - a handy tool from scikit-learn to apply some transformation to one column (*'quarter'*) and keep the rest unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = ColumnTransformer(\n",
    "     [('numeric', 'passthrough', ['period_num']),\n",
    "      ('categorical', OneHotEncoder(drop='first'), ['quarter'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_quarter_encoded = (\n",
    "    pd.DataFrame(columns = feature_transformer.fit(X_quarter).get_feature_names_out(),\n",
    "                 data = feature_transformer.fit_transform(X_quarter)\n",
    "                )\n",
    ")\n",
    "X_quarter_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further combine our preprocessing step with the model training using a Machine Learning pipeline from scikit-learn: a powerful way to keep both preprocessing and machine learning together in a single logical unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lm_quarter = Pipeline([\n",
    "    ('preprocess', feature_transformer),\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_quarter.fit(X_quarter, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol['pass_lin_q_pred'] = lm_quarter.predict(X_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schiphol[['total_passengers','pass_lin_q_pred']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R^2 is {round(lm_quarter.score(X_quarter, y),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple model appears to reasonably capture the observed seasonality (even if it fails to acknowledge the drop after the 2008-2008 Financial Crisis). Actual seasonality seems more complex than just fixed quarterly jumps or drops, but this approach already illustrates the main patterns. \n",
    "\n",
    "Moreover, it already allows us to separate seasonality from the trend and the residuals. We can compute the average seasonal effeect by averaging out the seasonal coefficients.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Seasonal coefficients {lm_quarter['model'].coef_[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_season_effect = (0.25 * lm_quarter['model'].coef_[1:]).sum()\n",
    "average_season_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this average seasonal effect to compute an ETS decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ets = (\n",
    "    schiphol\n",
    "    .loc[:,['total_passengers','pass_lin_q_pred']]\n",
    "    .rename(columns={\"total_passengers\": \"y_real\", \"pass_lin_q_pred\": \"y_hat\"})\n",
    "    .assign(trend = lambda df: lm_quarter['model'].coef_[0]*np.arange(len(df))\n",
    "                               + average_season_effect\n",
    "                               + lm_quarter['model'].intercept_,\n",
    "            seasonal = lambda df: df['y_hat'] - df['trend'],\n",
    "            residuals = lambda df: df['y_real'] - df['y_hat'])\n",
    ")\n",
    "simple_ets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ets[['y_real','y_hat','trend']].plot(figsize=(16,4))\n",
    "simple_ets[['seasonal']].plot(figsize=(16,2), c='m')\n",
    "simple_ets[['residuals']].plot(figsize=(16,2), c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having broken down a time series into its major components, we can now also *detrend* or *deseasonalize* it by subtracting the respective components. This can provide us with a clearer picture of what is going on over time aside from the trend and/or the seasonal fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ets = (simple_ets\n",
    "              .assign(deseasonalized = lambda df: df['y_real']-df['seasonal'],\n",
    "                      detrended = lambda df: df['y_real']-df['trend']))\n",
    "\n",
    "simple_ets[['deseasonalized']].plot(figsize=(16,3), c='g', label=\"deseasonalized time series\")\n",
    "simple_ets[['detrended']].plot(figsize=(16,3), c='m', label=\"detrended time series\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case it is unclear from the residuals plot, we can also inspect the autocorrelation plot for the residuals to see if we have likely missed some important (seasonal) patterns with out model. In this case, based on the remaining autocorrelation in the residuals, our seasonality representation is clearly a bit too simplistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "plot_acf(simple_ets['residuals'], lags=12, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='as1'></a>\n",
    "## Assignment: Monthly Dummies\n",
    "\n",
    "- Instead of the quarterly dummies, add monthly dummies\n",
    "- Add a post-2009 dummy\n",
    "- **Optional**: add interaction and polynomial terms for all features\n",
    "\n",
    "Fit the resulting model: is it a better fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can load an example answer below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/month_dummies.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gsf'></a>\n",
    "## Gradual Seasonal Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we are encoding seasonality with dummy variables, so an effect is either on or off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_quarter_encoded\n",
    "    .set_index(schiphol.index)\n",
    "    .drop(columns=\"numeric__period_num\")\n",
    "    .loc['Mar 2000':'Jan 2001']\n",
    "    .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, often seasonal effects do not come just as fixed spikes or drops. They may have gradually increasing and decreasing effects as their peak approaches and moves away in time. \n",
    "\n",
    "In such cases we may want to use a neat alternative to seasonal dummies: *gradual seasonal filters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of such features that we could create. \n",
    "\n",
    "### Linear\n",
    "\n",
    "A simple yet effective example are linear monthly spikes:\n",
    "\n",
    "$$ \\phi(x_i) = \\max( 1 - \\frac{| x - x^*|}{n} , 0)$$\n",
    "\n",
    "where $x$ is a given data point, $x^*$ is the peak of the current filter, and $n$ is the interval of growth/decline of the spike around the peak (e.g. 30 days). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsf_feature_maker(day, center_day, year_days = 365, n=30):\n",
    "    return np.max(\n",
    "        [np.fmax(-np.abs(day - center_day)/n + 1, 0),\n",
    "        np.fmax(-np.abs(day + year_days - center_day)/n + 1, 0),  #ensures continuity for December-January\n",
    "        np.fmax(-np.abs(day - year_days - center_day)/n + 1, 0)]) #ensures continuity for December-January"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a filter like this translates into a variable with values the closer to 1 (or to 0), the closer (or the further) a particular date is from the given peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [gsf_feature_maker(el, 15) for el in np.arange(365)]\n",
    "plt.figure(figsize = (17,3))\n",
    "plt.plot(base);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate filter can be assigned to each potential seasonal peak — each month in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = pd.date_range('2008-01-01', periods = 12, freq = 'M')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,3))\n",
    "for month in months:\n",
    "    ax.plot([gsf_feature_maker(el, month.dayofyear) for el in np.arange(365)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means an effect is not felt uniformly across a month, but increases/decreases depending on the distance from the desginated centre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guassian\n",
    "\n",
    "Another commonly used option are filters based on a *Gaussian distribution*:\n",
    "\n",
    "$$ \\phi(x_i) = \\exp [ - \\frac{1}{2\\alpha} (x-m_i)^2]$$\n",
    "\n",
    "where $x$ is a given data point, $m_i$ is the peak of the current filter, and $\\alpha$ is a parameter responsible for the spread of the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_feature_values(day, center_day, year_days = 365, alpha = 0.005):\n",
    "    return np.max(\n",
    "        [np.exp(-((day - center_day)**2) / 2*alpha),\n",
    "        np.exp(-((day + int(year_days) - center_day)**2) / 2*alpha)]) #ensures continuity for December-January"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a filter like this translates into a variable with values the closer to 1 (or to 0), the closer (or the further) a particular date is from the given peak. However, the effect is much smoother.\n",
    "\n",
    "Depending on $\\alpha$, very steep or very gradual filters can be created.  Such gradual filters could be especially handy when dealing with daily (or even hourly) data that typically exhibits more gradual seasonal effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = [rbf_feature_values(el, 350, alpha = 0.001) for el in np.arange(365)]\n",
    "plt.figure(figsize = (17,3))\n",
    "plt.plot(base);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a separate filter can be assigned to each potential seasonal peak — each month in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = pd.date_range('2008-01-01', periods = 12, freq = 'M')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,3))\n",
    "for month in months:\n",
    "    ax.plot([rbf_feature_values(el, month.dayofyear) for el in np.arange(365)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with a seasonal filter\n",
    "\n",
    "We will use the Gaussian filter to add seasonal features to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_rbf = (\n",
    "    schiphol\n",
    "    [['total_passengers', 'after2009']]\n",
    "    .assign(month = lambda df: df.index.month)\n",
    ")\n",
    "schiphol_rbf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 12 RBF features to the dataset\n",
    "from calendar import month_name\n",
    "month_in_days = [date.dayofyear for date in schiphol_rbf.index[:12]]\n",
    "\n",
    "for i in range(12):\n",
    "    feature_name = month_name[i+1]\n",
    "    peak = month_in_days[i]\n",
    "    schiphol_rbf[feature_name] = [rbf_feature_values(date.dayofyear, peak).round(2) for date in schiphol_rbf.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 12 extra features corresponding to the effects of Gaussians filters for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_rbf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can illustrate how such RBF features look like for our dataset, where we only have monthly (not-daily) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_rbf[['April', 'October']].loc['2014':].plot(figsize=(17,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can train a model using these RBF features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var = np.arange(len(schiphol_rbf.index)).reshape(-1, 1)\n",
    "X_rbf = np.c_[time_var, schiphol_rbf.iloc[:,3:]]\n",
    "y = schiphol_rbf['total_passengers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_rbf = LinearRegression().fit(X_rbf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_rbf['pass_rbf_pred'] = lm_rbf.predict(X_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol_rbf[['total_passengers','pass_rbf_pred']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R^2 is {round(lm_rbf.score(X_rbf, y),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF with Scikit-Lego\n",
    "\n",
    "In case you do not want to create such RBF features manually, this preprocessing method is already implemented in a library called [Scikit-Lego](https://scikit-lego.netlify.app/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "\n",
    "rbf = RepeatingBasisFunction(n_periods=12,\n",
    "                             remainder='passthrough',\n",
    "                             column='month',\n",
    "                             input_range=(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = rbf.fit_transform(schiphol_rbf[['month']])\n",
    "sklego_rbf = pd.DataFrame(columns=month_name[1:], data=Xt, index=schiphol_rbf.index).round(2)\n",
    "sklego_rbf.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklego_rbf[['April', 'October']].loc['2014':].plot(figsize=(17,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradual Seasonal Filtering Summary\n",
    "\n",
    "**Pros** \n",
    "\n",
    "- Simple feature engineering trick\n",
    "- All variables are interpretable\n",
    "- Seasonal effects can be quantified\n",
    "- Can filter out the long term seasonality, other fluctuations can be modeled separately\n",
    "\n",
    "**Cons** \n",
    "\n",
    "- The model can get a bit biased to beliefs about seasonality\n",
    "- The model may have issues if the seasonality changes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ncs'></a>\n",
    "## Non-Constant Seasonality\n",
    "\n",
    "One drawback of simple RBF features that we have used above is that they model constant seasonality, while this may often be an incorrect assumption. We have seen above that the fitted cycles are perhaps too large for the first few years and too small for the last few years.\n",
    "\n",
    "A simple solution to this problem is to create a new set of similar rbf features but then multiplied by the time period. This will allow fitted seasonal cycles to scale with time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='as2'></a>\n",
    "## Assignment: Non-Constant Seasonality \n",
    "\n",
    "- Add 12 new rbf and time interaction features (rbf x time) to our previous model. \n",
    "- Also add the after2009 dummy. \n",
    "- Fit the model and plot the results.\n",
    "\n",
    "What changed about seasonality?\n",
    "\n",
    "*you can load the answer below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/nc_seasonality.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sum'></a>\n",
    "## Summary\n",
    "\n",
    "We have covered: \n",
    "\n",
    "- How time series data can be broken down into components:\n",
    "    - Trends \n",
    "    - Seasonality \n",
    "    - Non-cyclical components \n",
    "    - Residuals \n",
    "- How to model the trend using linear regression.\n",
    "- How to model seasonality using dummy variables and gradual seaonal filters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
